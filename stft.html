<!DOCTYPE html>
<html lang="ja">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Web Audio API</title>
    </head>
    <body>
        <h1>音源の作成　ファイルをbufferとして読み込む</h1>
        <button id="play">play</button>
        <button id="stop">stop</button>
    </body>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
    <script>
        window.AudioContext = window.AudioContext || window.webkitAudioContext;
        const ctx = new AudioContext();
    
        let sampleSource;
        // 再生中でtrue
        let isPlaying = false;

        const wav_file = "./BASIC5000_0001.wav";
        // 音源を取得しAudioBuffer形式に変換して返す関数
        async function setupSample() {
            // const response = await fetch("../BASIC5000_0001.wav");
            const response = await fetch(wav_file);
            const arrayBuffer = await response.arrayBuffer();
            // Web Audio APIで使える形式に変換
            const audioBuffer = await ctx.decodeAudioData(arrayBuffer);
            return audioBuffer;
        }
        // AudioBufferをctxに接続し再生する関数
        function playSample(ctx, audioBuffer) {
            sampleSource = ctx.createBufferSource();
            // 変換されたバッファーを音源として設定
            sampleSource.buffer = audioBuffer;
            // 出力につなげる
            sampleSource.connect(ctx.destination);
            sampleSource.start();
            isPlaying = true
        }
        
        async function stft() {
            var frame_size = 25;
            var frame_shift = 10;
            const analyser = ctx.createAnalyser();
            const source = ctx.createBufferSource();
            const file = await fetch(wav_file);
            const arraybuffer = await file.arrayBuffer();
            const audiobuffer = await ctx.decodeAudioData(arraybuffer);
            const sample_frequency = audiobuffer.sampleRate;
            const num_samples = sample_frequency * audiobuffer.duration;
            console.log(audiobuffer);
            // console.log(audiobuffer.getChannelData());
            
            // var buffer = new Uint8Array(num_samples);
            // analyser.getByteFrequencyData(buffer);
            // console.log(buffer);
            
            console.log(sample_frequency);
            // console.log(num_samples === audiobuffer.length);
            console.log(num_samples);
            frame_size = parseInt(sample_frequency * frame_size * 0.001);
            frame_shift = parseInt(sample_frequency * frame_shift * 0.001);
            
            var fft_size = 1;
            while(fft_size < frame_size){
                fft_size *= 2;
            }
            analyser.fftsize = 1 << fft_size;         // fft_size = 2048
            var length = analyser.frequencyBinCount;  // length = 1024
            
            const num_frames = Math.trunc((num_samples - frame_size) / frame_shift) + 1;
            
            var spectrogram = tf.zeros([num_frames, parseInt(fft_size / 2) + 1]);
            
            // for (var frame_idx = 0; frame_idx < num_frames; frame_idx++) {
            //     var start_index = frame_idx * frame_shift;
            //     var frame = 
            // }
        }
        
        stft();
        
        document.querySelector("#play").addEventListener("click", async () => {
            // 再生中なら二重に再生されないようにする
            if(isPlaying) return;
            const sample = await setupSample();
            playSample(ctx, sample);
        });

        // oscillatorを破棄し再生を停止する
        document.querySelector("#stop").addEventListener("click", async () => {
            sampleSource?.stop();
            isPlaying = false
        });
        
    </script>
    <style>
        div{
            padding-bottom: 40px;
            border-bottom: 2px solid #666;
        }
    </style>
</html>
